{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc5627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import pyfpgrowth\n",
    "\n",
    "# Function to read CSV file and convert it into a list of transactions\n",
    "def read_transactions(file_path):\n",
    "    transactions = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = pd.read_csv(file)\n",
    "        for index, row in csv_reader.iterrows():\n",
    "            transactions.append(row['Transaction'].split(', '))\n",
    "    return transactions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Brute force method to find frequent itemsets\n",
    "def brute_force(transactions, support_threshold):\n",
    "    items = set(item for transaction in transactions for item in transaction)\n",
    "    itemsets = []\n",
    "    for i in range(1, len(items) + 1):\n",
    "        itemsets.extend(itertools.combinations(items, i))\n",
    "    frequent_itemsets = {}\n",
    "    for itemset in itemsets:\n",
    "        frequency = sum(1 for transaction in transactions if set(itemset).issubset(set(transaction)))\n",
    "        if frequency / len(transactions) >= support_threshold:\n",
    "            frequent_itemsets[itemset] = frequency\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Function to convert list of transactions into the right format for MLxtend\n",
    "def convert_to_mlxtend_format(transactions):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    return df\n",
    "\n",
    "# Function to run Apriori algorithm and find frequent itemsets\n",
    "def run_apriori(transactions, support_threshold):\n",
    "    df = convert_to_mlxtend_format(transactions)\n",
    "    frequent_itemsets = apriori(df, min_support=support_threshold, use_colnames=True)\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Function to run FP-Growth algorithm and find frequent itemsets\n",
    "def run_fpgrowth(transactions, support_threshold):\n",
    "    patterns = pyfpgrowth.find_frequent_patterns(transactions, support_threshold * len(transactions))\n",
    "    frequent_itemsets = pd.DataFrame(list(patterns.items()), columns=['itemsets', 'support'])\n",
    "    frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(frozenset)\n",
    "    return frequent_itemsets\n",
    "\n",
    "# Function to generate association rules from frequent itemsets\n",
    "def generate_rules(frequent_itemsets, transactions, confidence_threshold):\n",
    "    df = convert_to_mlxtend_format(transactions)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_threshold,support_only=True)\n",
    "    rules = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
    "    return rules\n",
    "\n",
    "# Function to compare results and performance time of all three algorithms\n",
    "def compare_algorithms(file_path, support_threshold, confidence_threshold):\n",
    "    transactions = read_transactions(file_path)\n",
    "    start_time = time.time()\n",
    "    brute_force_itemsets = brute_force(transactions, support_threshold)\n",
    "    brute_force_time = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "    apriori_itemsets = run_apriori(transactions, support_threshold)\n",
    "    apriori_rules = generate_rules(apriori_itemsets, transactions, confidence_threshold)\n",
    "    apriori_time = time.time() - start_time\n",
    "    start_time = time.time()\n",
    "    fpgrowth_itemsets = run_fpgrowth(transactions, support_threshold)\n",
    "    fpgrowth_rules = generate_rules(fpgrowth_itemsets, transactions, confidence_threshold)\n",
    "    fpgrowth_time = time.time() - start_time\n",
    "    print(f\"Brute Force Method: {len(brute_force_itemsets)} frequent itemsets found in {brute_force_time:.5f} seconds.\")\n",
    "    print(f\"Apriori Algorithm: {len(apriori_itemsets)} frequent itemsets and {len(apriori_rules)} rules found in {apriori_time:.5f} seconds.\")\n",
    "    print(f\"FP-Growth Algorithm: {len(fpgrowth_itemsets)} frequent itemsets and {len(fpgrowth_rules)} rules found in {fpgrowth_time:.5f} seconds.\")\n",
    "    return brute_force_itemsets, apriori_rules, fpgrowth_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903f4048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the support threshold (as a fraction): 0.2\n",
      "Enter the confidence threshold (as a fraction): 0.4\n",
      "Select a dataset (amazon, best_buy, generic, k_mart, nike): nike\n",
      "Select an algorithm (apriori, fpgrowth, bruteforce): fpgrowth\n",
      "\n",
      "Processing Nike.csv\n",
      "Brute Force Method: 439 frequent itemsets found in 0.08944 seconds.\n",
      "Apriori Algorithm: 439 frequent itemsets and 64 rules found in 0.01919 seconds.\n",
      "FP-Growth Algorithm: 429 frequent itemsets and 9566 rules found in 0.03675 seconds.\n",
      "Number of rules generated by Fpgrowth: 9566\n"
     ]
    }
   ],
   "source": [
    "# Main function to orchestrate the analysis\n",
    "def main():\n",
    "    support_threshold = float(input(\"Enter the support threshold (as a fraction): \"))\n",
    "    confidence_threshold = float(input(\"Enter the confidence threshold (as a fraction): \"))\n",
    "\n",
    "    dataset_options = {\n",
    "        'amazon': 'Amazon.csv',\n",
    "        'best_buy': 'Best_Buy.csv',\n",
    "        'generic': 'Generic.csv',\n",
    "        'k_mart': 'K-Mart.csv',\n",
    "        'nike': 'Nike.csv'\n",
    "    }\n",
    "    selected_dataset = input(f\"Select a dataset ({', '.join(dataset_options.keys())}): \").lower()\n",
    "\n",
    "    if selected_dataset not in dataset_options:\n",
    "        print(\"Invalid dataset selection. Exiting.\")\n",
    "        return\n",
    "\n",
    "    file_path = dataset_options[selected_dataset]\n",
    "\n",
    "    algorithm_options = ['apriori', 'fpgrowth', 'bruteforce']\n",
    "    selected_algorithm = input(f\"Select an algorithm ({', '.join(algorithm_options)}): \").lower()\n",
    "\n",
    "    if selected_algorithm not in algorithm_options:\n",
    "        print(\"Invalid algorithm selection. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nProcessing {file_path}\")\n",
    "\n",
    "    if selected_algorithm == 'bruteforce':\n",
    "        brute_force_itemsets, _, _ = compare_algorithms(file_path, support_threshold, confidence_threshold)\n",
    "        print(f\"Number of rules generated by Brute Force: {len(brute_force_itemsets)}\")\n",
    "    else:\n",
    "        _, apriori_rules, fpgrowth_rules = compare_algorithms(file_path, support_threshold, confidence_threshold)\n",
    "        print(f\"Number of rules generated by {selected_algorithm.capitalize()}: {len(apriori_rules if selected_algorithm == 'apriori' else fpgrowth_rules)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad5e016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
